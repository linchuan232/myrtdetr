# Ultralytics YOLO ğŸš€, AGPL-3.0 license
"""Block modules."""

import torch
import torch.nn as nn
import torch.nn.functional as F
from collections import OrderedDict
import math
import numpy as np
from .conv import Conv, DWConv, GhostConv, LightConv, RepConv
from .transformer import TransformerBlock

__all__ = ('DFL', 'HGBlock', 'HGStem', 'SPP', 'SPPF', 'C1', 'C2', 'C3', 'C2f', 'C3x', 'C3TR', 'C3Ghost',
           'GhostBottleneck', 'Bottleneck', 'BottleneckCSP', 'Proto', 'RepC3', 'ConvNormLayer', 'BasicBlock', 
           'BottleNeck', 'Blocks','C2f_MambaOut_DSA','BasicBlock_Hybrid_Full','GatedFusion_Lite','GatedFusion_Tiny')

def autopad(k, p=None, d=1):
    """è‡ªåŠ¨å¡«å……ä»¥ä¿æŒè¾“å‡ºå°ºå¯¸"""
    if d > 1:
        k = d * (k - 1) + 1 if isinstance(k, int) else [d * (x - 1) + 1 for x in k]
    if p is None:
        p = k // 2 if isinstance(k, int) else [x // 2 for x in k]
    return p


class Conv(nn.Module):
    """æ ‡å‡†å·ç§¯å±‚ + BN + æ¿€æ´»"""
    default_act = nn.SiLU()

    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, d=1, act=True):
        super().__init__()
        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p, d), groups=g, dilation=d, bias=False)
        self.bn = nn.BatchNorm2d(c2)
        self.act = (
            self.default_act if act is True
            else act if isinstance(act, nn.Module)
            else nn.Identity()
        )

    def forward(self, x):
        return self.act(self.bn(self.conv(x)))


# ============================================================================
# é¢‘åŸŸå¤„ç†ç»„ä»¶ï¼ˆæ¥è‡ª SFS_Convï¼‰
# ============================================================================

class FractionalGaborFilter(nn.Module):
    """åˆ†æ•°é˜¶Gaboræ»¤æ³¢å™¨"""
    def __init__(self, in_channels, out_channels, kernel_size, order, angles, scales):
        super().__init__()
        self.real_weights = nn.ParameterList()
        
        for angle in angles:
            for scale in scales:
                real_weight = self.generate_fractional_gabor(
                    in_channels, out_channels, kernel_size, order, angle, scale
                )
                self.real_weights.append(nn.Parameter(real_weight))

    def generate_fractional_gabor(self, in_channels, out_channels, size, order, angle, scale):
        x, y = np.meshgrid(np.linspace(-1, 1, size[0]), np.linspace(-1, 1, size[1]))
        x_theta = x * np.cos(angle) + y * np.sin(angle)
        y_theta = -x * np.sin(angle) + y * np.cos(angle)
        
        real_part = np.exp(-((x_theta**2 + (y_theta / scale) ** 2) ** order)) * \
                    np.cos(2 * np.pi * x_theta / scale)
        
        real_weight = torch.tensor(real_part, dtype=torch.float32).view(1, 1, size[0], size[1])
        real_weight = real_weight.repeat(out_channels, 1, 1, 1)
        return real_weight

    def forward(self, x):
        real_result = sum(weight * x for weight in self.real_weights)
        return real_result


class FrequencyUnit(nn.Module):
    """é¢‘åŸŸå¤„ç†å•å…ƒ"""
    def __init__(self, in_channels, out_channels, kernel_size=(3, 3), order=0.25):
        super().__init__()
        angles = [0, np.pi/4, np.pi/2]
        scales = [1, 2]
        
        self.gabor = FractionalGaborFilter(
            in_channels, out_channels, kernel_size, order, angles, scales
        )
        self.t = nn.Parameter(
            torch.randn(out_channels, in_channels, kernel_size[0], kernel_size[1]),
            requires_grad=True,
        )
        nn.init.normal_(self.t, std=0.02)
        self.act = nn.GELU()

    def forward(self, x):
        out = self.gabor(self.t)
        out = F.conv2d(x, out, stride=1, padding=(out.shape[-2] - 1) // 2)
        out = self.act(out)
        return out


# ============================================================================
# é—¨æ§ç©ºé—´å•å…ƒï¼ˆæ¥è‡ª GatedCNNBlockï¼‰
# ============================================================================

class GatedSpatialUnit(nn.Module):
    """é—¨æ§ç©ºé—´å¤„ç†å•å…ƒ"""
    def __init__(self, dim, kernel_size=7, conv_ratio=0.5, expansion_ratio=2.0):
        super().__init__()
        hidden = int(expansion_ratio * dim)
        self.fc1 = nn.Linear(dim, hidden * 2)
        self.act = nn.GELU()
        
        conv_channels = int(conv_ratio * dim)
        self.split_indices = (hidden, hidden - conv_channels, conv_channels)
        
        self.conv = nn.Conv2d(
            conv_channels, conv_channels,
            kernel_size=kernel_size,
            padding=kernel_size // 2,
            groups=conv_channels
        )
        self.fc2 = nn.Linear(hidden, dim)

    def forward(self, x):
        # x: [B, C, H, W] -> [B, H, W, C]
        x = x.permute(0, 2, 3, 1)
        
        g, i, c = torch.split(self.fc1(x), self.split_indices, dim=-1)
        c = c.permute(0, 3, 1, 2)
        c = self.conv(c)
        c = c.permute(0, 2, 3, 1)
        
        x = self.fc2(self.act(g) * torch.cat((i, c), dim=-1))
        return x.permute(0, 3, 1, 2)


# ============================================================================
# HybridBottleneck ä¸‰ä¸ªç‰ˆæœ¬
# ============================================================================

class HybridBottleneck_Full(nn.Module):
    """å®Œæ•´ç‰ˆæ··åˆç“¶é¢ˆå— - ç©ºé—´+é¢‘åŸŸ"""
    def __init__(self, c1, c2, shortcut=True, kernel_size=7, expansion=0.5):
        super().__init__()
        c_ = int(c2 * expansion)
        
        self.cv1 = Conv(c1, c_, 1, 1)
        self.gated_spatial = GatedSpatialUnit(c_, kernel_size=kernel_size, conv_ratio=0.5)
        self.frequency = FrequencyUnit(c_, c_, kernel_size=(3, 3))
        
        self.fusion = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(c_ * 2, c_ // 2, 1),
            nn.GELU(),
            nn.Conv2d(c_ // 2, c_ * 2, 1),
            nn.Sigmoid()
        )
        
        self.cv2 = Conv(c_ * 2, c2, 1, 1)
        self.add = shortcut and c1 == c2

    def forward(self, x):
        feat = self.cv1(x)
        spatial_feat = self.gated_spatial(feat)
        freq_feat = self.frequency(feat)
        combined = torch.cat([spatial_feat, freq_feat], dim=1)
        attention = self.fusion(combined)
        fused = combined * attention
        out = self.cv2(fused)
        return x + out if self.add else out


class HybridBottleneck_Lite(nn.Module):
    """è½»é‡ç‰ˆæ··åˆç“¶é¢ˆå— - é€‰æ‹©æ€§é¢‘åŸŸ"""
    def __init__(self, c1, c2, shortcut=True, kernel_size=7, expansion=0.5):
        super().__init__()
        c_ = int(c2 * expansion)
        c_freq = c_ // 2
        
        self.cv1 = Conv(c1, c_, 1, 1)
        self.gated_spatial = GatedSpatialUnit(c_, kernel_size=kernel_size, conv_ratio=0.5)
        self.frequency = FrequencyUnit(c_freq, c_freq, kernel_size=(3, 3))
        
        self.freq_gate = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(c_freq, c_freq, 1),
            nn.Sigmoid()
        )
        
        self.cv2 = Conv(c_ + c_freq, c2, 1, 1)
        self.add = shortcut and c1 == c2

    def forward(self, x):
        feat = self.cv1(x)
        spatial_feat = self.gated_spatial(feat)
        freq_input = feat[:, :feat.size(1)//2, :, :]
        freq_feat = self.frequency(freq_input)
        freq_feat = freq_feat * self.freq_gate(freq_feat)
        combined = torch.cat([spatial_feat, freq_feat], dim=1)
        out = self.cv2(combined)
        return x + out if self.add else out


class HybridBottleneck_Fast(nn.Module):
    """å¿«é€Ÿç‰ˆæ··åˆç“¶é¢ˆå— - ä»…é—¨æ§"""
    def __init__(self, c1, c2, shortcut=True, kernel_size=7, expansion=0.5):
        super().__init__()
        c_ = int(c2 * expansion)
        
        self.cv1 = Conv(c1, c_, 1, 1)
        self.gated_spatial = GatedSpatialUnit(c_, kernel_size=kernel_size, conv_ratio=0.5)
        self.cv2 = Conv(c_, c2, 1, 1)
        self.add = shortcut and c1 == c2

    def forward(self, x):
        feat = self.cv1(x)
        out = self.gated_spatial(feat)
        out = self.cv2(out)
        return x + out if self.add else out


# ============================================================================
# C2f_Hybrid ä¸‰ä¸ªç‰ˆæœ¬ - CSPæ¶æ„
# ============================================================================

class C2f_Hybrid_Full(nn.Module):
    """
    C2f with HybridBottleneck_Full
    CSP Bottleneck with 2 convolutions - å®Œæ•´ç‰ˆ
    
    ç‰¹ç‚¹:
    - ä½¿ç”¨ HybridBottleneck_Full ä½œä¸ºåŸºç¡€æ¨¡å—
    - å®Œæ•´çš„ç©ºé—´+é¢‘åŸŸå¤„ç†
    - CSPæ¶æ„æä¾›æ›´å¥½çš„æ¢¯åº¦æµ
    - é€‚åˆå¯¹ç²¾åº¦è¦æ±‚é«˜çš„ä»»åŠ¡
    
    å‚æ•°:
        c1: è¾“å…¥é€šé“æ•°
        c2: è¾“å‡ºé€šé“æ•°
        n: Bottleneckæ•°é‡
        shortcut: æ˜¯å¦ä½¿ç”¨shortcutè¿æ¥
        g: åˆ†ç»„å·ç§¯çš„ç»„æ•°ï¼ˆä¿ç•™å‚æ•°ï¼Œå®é™…åœ¨HybridBottleneckä¸­ä¸ä½¿ç”¨ï¼‰
        e: expansion ratioï¼Œéšè—å±‚é€šé“æ‰©å±•æ¯”ä¾‹
    """
    def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5):
        super().__init__()
        self.c = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, 2 * self.c, 1, 1)
        self.cv2 = Conv((2 + n) * self.c, c2, 1)
        
        # ä½¿ç”¨ HybridBottleneck_Full æ›¿ä»£åŸå§‹ Bottleneck
        self.m = nn.ModuleList(
            HybridBottleneck_Full(
                self.c, 
                self.c, 
                shortcut=shortcut,
                kernel_size=7,
                expansion=1.0
            ) for _ in range(n)
        )

    def forward(self, x):
        """å‰å‘ä¼ æ’­ - CSPæ¶æ„"""
        y = list(self.cv1(x).chunk(2, 1))
        y.extend(m(y[-1]) for m in self.m)
        return self.cv2(torch.cat(y, 1))

    def forward_split(self, x):
        """ä½¿ç”¨split()è€Œéchunk()çš„å‰å‘ä¼ æ’­"""
        y = list(self.cv1(x).split((self.c, self.c), 1))
        y.extend(m(y[-1]) for m in self.m)
        return self.cv2(torch.cat(y, 1))


class C2f_Hybrid_Lite(nn.Module):
    """
    C2f with HybridBottleneck_Lite
    CSP Bottleneck with 2 convolutions - è½»é‡ç‰ˆ â­ æ¨è
    
    ç‰¹ç‚¹:
    - ä½¿ç”¨ HybridBottleneck_Lite ä½œä¸ºåŸºç¡€æ¨¡å—
    - é€‰æ‹©æ€§çš„é¢‘åŸŸå¤„ç†
    - å¹³è¡¡ç²¾åº¦å’Œæ•ˆç‡
    - é€‚åˆå¤§å¤šæ•°åº”ç”¨åœºæ™¯
    """
    def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5):
        super().__init__()
        self.c = int(c2 * e)
        self.cv1 = Conv(c1, 2 * self.c, 1, 1)
        self.cv2 = Conv((2 + n) * self.c, c2, 1)
        
        # ä½¿ç”¨ HybridBottleneck_Lite
        self.m = nn.ModuleList(
            HybridBottleneck_Lite(
                self.c, 
                self.c, 
                shortcut=shortcut,
                kernel_size=7,
                expansion=1.0
            ) for _ in range(n)
        )

    def forward(self, x):
        y = list(self.cv1(x).chunk(2, 1))
        y.extend(m(y[-1]) for m in self.m)
        return self.cv2(torch.cat(y, 1))

    def forward_split(self, x):
        y = list(self.cv1(x).split((self.c, self.c), 1))
        y.extend(m(y[-1]) for m in self.m)
        return self.cv2(torch.cat(y, 1))


class C2f_Hybrid_Fast(nn.Module):
    """
    C2f with HybridBottleneck_Fast
    CSP Bottleneck with 2 convolutions - å¿«é€Ÿç‰ˆ
    
    ç‰¹ç‚¹:
    - ä½¿ç”¨ HybridBottleneck_Fast ä½œä¸ºåŸºç¡€æ¨¡å—
    - ä»…é—¨æ§æœºåˆ¶ï¼Œæ— é¢‘åŸŸå¤„ç†
    - æœ€å¿«çš„æ¨ç†é€Ÿåº¦
    - é€‚åˆå®æ—¶åº”ç”¨
    """
    def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5):
        super().__init__()
        self.c = int(c2 * e)
        self.cv1 = Conv(c1, 2 * self.c, 1, 1)
        self.cv2 = Conv((2 + n) * self.c, c2, 1)
        
        # ä½¿ç”¨ HybridBottleneck_Fast
        self.m = nn.ModuleList(
            HybridBottleneck_Fast(
                self.c, 
                self.c, 
                shortcut=shortcut,
                kernel_size=7,
                expansion=1.0
            ) for _ in range(n)
        )

    def forward(self, x):
        y = list(self.cv1(x).chunk(2, 1))
        y.extend(m(y[-1]) for m in self.m)
        return self.cv2(torch.cat(y, 1))

    def forward_split(self, x):
        y = list(self.cv1(x).split((self.c, self.c), 1))
        y.extend(m(y[-1]) for m in self.m)
        return self.cv2(torch.cat(y, 1))


# ============================================================================
# ç”¨äºæ›¿ä»£BasicBlockçš„åŒ…è£…ç±»
# ============================================================================

class BasicBlock_Hybrid_Full(nn.Module):
    """
    ç”¨C2f_Hybrid_Fullæ›¿ä»£BasicBlockçš„åŒ…è£…ç±»
    å¯ç›´æ¥åœ¨ResNetä¸­æ›¿æ¢åŸå§‹BasicBlock
    
    ä½¿ç”¨æ–¹æ³•:
        # åŸå§‹: block = BasicBlock(64, 64)
        # æ›¿æ¢: block = BasicBlock_Hybrid_Full(64, 64)
    """
    expansion = 1  # ä¿æŒä¸BasicBlockä¸€è‡´
    
    def __init__(self, inplanes, planes, stride=1, downsample=None, n=1):
        super().__init__()
        
        # å¦‚æœstride!=1ï¼Œéœ€è¦ä¸‹é‡‡æ ·
        if stride != 1 or inplanes != planes:
            self.downsample = nn.Sequential(
                nn.Conv2d(inplanes, planes, 1, stride, bias=False),
                nn.BatchNorm2d(planes)
            )
        else:
            self.downsample = downsample
        
        # ä½¿ç”¨C2f_Hybrid_Full
        # å½“stride=1æ—¶ï¼Œç›´æ¥ä½¿ç”¨C2f
        # å½“stride!=1æ—¶ï¼Œå…ˆä¸‹é‡‡æ ·å†ä½¿ç”¨C2f
        if stride == 1:
            self.c2f = C2f_Hybrid_Full(inplanes, planes, n=n, shortcut=True, e=0.5)
        else:
            # å…ˆé€šè¿‡å·ç§¯ä¸‹é‡‡æ ·
            self.stride_conv = nn.Sequential(
                Conv(inplanes, planes, 3, stride),
            )
            self.c2f = C2f_Hybrid_Full(planes, planes, n=n, shortcut=True, e=0.5)
        
        self.stride = stride

    def forward(self, x):
        identity = x
        
        if self.stride != 1:
            # å…ˆä¸‹é‡‡æ ·
            out = self.stride_conv(x)
            out = self.c2f(out)
            if self.downsample is not None:
                identity = self.downsample(x)
        else:
            out = self.c2f(x)
        
        # æ®‹å·®è¿æ¥
        if identity.shape == out.shape:
            out += identity
        elif self.downsample is not None:
            out += self.downsample(identity)
            
        return out


class BasicBlock_Hybrid_Lite(nn.Module):
    """
    ç”¨C2f_Hybrid_Liteæ›¿ä»£BasicBlockçš„åŒ…è£…ç±» â­ æ¨è
    """
    expansion = 1
    
    def __init__(self, inplanes, planes, stride=1, downsample=None, n=1):
        super().__init__()
        
        if stride != 1 or inplanes != planes:
            self.downsample = nn.Sequential(
                nn.Conv2d(inplanes, planes, 1, stride, bias=False),
                nn.BatchNorm2d(planes)
            )
        else:
            self.downsample = downsample
        
        if stride == 1:
            self.c2f = C2f_Hybrid_Lite(inplanes, planes, n=n, shortcut=True, e=0.5)
        else:
            self.stride_conv = nn.Sequential(
                Conv(inplanes, planes, 3, stride),
            )
            self.c2f = C2f_Hybrid_Lite(planes, planes, n=n, shortcut=True, e=0.5)
        
        self.stride = stride

    def forward(self, x):
        identity = x
        
        if self.stride != 1:
            out = self.stride_conv(x)
            out = self.c2f(out)
            if self.downsample is not None:
                identity = self.downsample(x)
        else:
            out = self.c2f(x)
        
        if identity.shape == out.shape:
            out += identity
        elif self.downsample is not None:
            out += self.downsample(identity)
            
        return out


class BasicBlock_Hybrid_Fast(nn.Module):
    """
    ç”¨C2f_Hybrid_Fastæ›¿ä»£BasicBlockçš„åŒ…è£…ç±»
    """
    expansion = 1
    
    def __init__(self, inplanes, planes, stride=1, downsample=None, n=1):
        super().__init__()
        
        if stride != 1 or inplanes != planes:
            self.downsample = nn.Sequential(
                nn.Conv2d(inplanes, planes, 1, stride, bias=False),
                nn.BatchNorm2d(planes)
            )
        else:
            self.downsample = downsample
        
        if stride == 1:
            self.c2f = C2f_Hybrid_Fast(inplanes, planes, n=n, shortcut=True, e=0.5)
        else:
            self.stride_conv = nn.Sequential(
                Conv(inplanes, planes, 3, stride),
            )
            self.c2f = C2f_Hybrid_Fast(planes, planes, n=n, shortcut=True, e=0.5)
        
        self.stride = stride

    def forward(self, x):
        identity = x
        
        if self.stride != 1:
            out = self.stride_conv(x)
            out = self.c2f(out)
            if self.downsample is not None:
                identity = self.downsample(x)
        else:
            out = self.c2f(x)
        
        if identity.shape == out.shape:
            out += identity
        elif self.downsample is not None:
            out += self.downsample(identity)
            
        return out


# Assuming Conv is defined elsewhere, e.g., a simple Conv wrapper
class Conv(nn.Module):
    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):
        super().__init__()
        p = k // 2 if p is None else p
        self.conv = nn.Conv2d(c1, c2, k, s, p, groups=g, bias=False)
        self.bn = nn.BatchNorm2d(c2)
        self.act = nn.SiLU() if act is True else (act if isinstance(act, nn.Module) else nn.Identity())

    def forward(self, x):
        return self.act(self.bn(self.conv(x)))

# DropPath definition (required for GatedCNNBlockAdapted)
class DropPath(nn.Module):
    def __init__(self, drop_prob=None):
        super(DropPath, self).__init__()
        self.drop_prob = drop_prob

    def forward(self, x):
        if self.drop_prob == 0. or not self.training:
            return x
        keep_prob = 1 - self.drop_prob
        shape = (x.shape[0],) + (1,) * (x.ndim - 1)
        random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)
        random_tensor.floor_()
        output = x.div(keep_prob) * random_tensor
        return output

# GatedCNNBlockAdapted (channel-first adapted)
class GatedCNNBlockAdapted(nn.Module):
    def __init__(self, dim, expansion_ratio=8/3, kernel_size=3, conv_ratio=1.0, drop_path=0.):
        super().__init__()
        self.norm = nn.BatchNorm2d(dim)
        hidden = int(expansion_ratio * dim)
        self.fc1 = nn.Conv2d(dim, hidden * 2, 1)
        self.act = nn.GELU()
        conv_channels = int(conv_ratio * dim)
        self.split_indices = (hidden, hidden - conv_channels, conv_channels)
        self.conv = nn.Conv2d(conv_channels, conv_channels, kernel_size=kernel_size, padding=kernel_size//2, groups=conv_channels)
        self.fc2 = nn.Conv2d(hidden, dim, 1)
        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()

    def forward(self, x):
        shortcut = x
        x = self.norm(x)
        g, i, c = torch.split(self.fc1(x), self.split_indices, dim=1)
        c = self.conv(c)
        x = self.fc2(self.act(g) * torch.cat((i, c), dim=1))
        x = self.drop_path(x)
        return x + shortcut

# GatedDSABlock (adapted to match Bottleneck interface)
class GatedDSABlock(nn.Module):
    def __init__(self, c1, c2, shortcut=True, g=1, k=(3, 3), e=1.0, drop_path=0.):
        super().__init__()
        c_ = int(c2 * e)  # hidden channels, matching original Bottleneck
        self.cv1 = Conv(c1, c_, k[0], 1)
        self.cv2 = Conv(c_, c2, k[1], 1, g=g)
        self.spatial_gating_unit = GatedCNNBlockAdapted(c2, kernel_size=k[1], drop_path=drop_path)
        self.add = shortcut and c1 == c2

    def forward(self, x):
        out = self.cv2(self.cv1(x))
        out = self.spatial_gating_unit(out)
        return x + out if self.add else out

# Modified C2f with GatedDSABlock replacement
class C2f_MambaOut_DSA(nn.Module):
    """Faster Implementation of CSP Bottleneck with 2 convolutions."""

    def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5):
        """Initialize CSP bottleneck layer with two convolutions with arguments ch_in, ch_out, number, shortcut, groups,
        expansion.
        """
        super().__init__()
        self.c = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, 2 * self.c, 1, 1)
        self.cv2 = Conv((2 + n) * self.c, c2, 1)  # optional act=FReLU(c2)
        self.m = nn.ModuleList(GatedDSABlock(self.c, self.c, shortcut, g, k=((3, 3), (3, 3)), e=1.0) for _ in range(n))

    def forward(self, x):
        """Forward pass through C2f layer."""
        y = list(self.cv1(x).chunk(2, 1))
        y.extend(m(y[-1]) for m in self.m)
        return self.cv2(torch.cat(y, 1))

    def forward_split(self, x):
        """Forward pass using split() instead of chunk()."""
        y = list(self.cv1(x).split((self.c, self.c), 1))
        y.extend(m(y[-1]) for m in self.m)
        return self.cv2(torch.cat(y, 1))



class DFL(nn.Module):
    """
    Integral module of Distribution Focal Loss (DFL).

    Proposed in Generalized Focal Loss https://ieeexplore.ieee.org/document/9792391
    """

    def __init__(self, c1=16):
        """Initialize a convolutional layer with a given number of input channels."""
        super().__init__()
        self.conv = nn.Conv2d(c1, 1, 1, bias=False).requires_grad_(False)
        x = torch.arange(c1, dtype=torch.float)
        self.conv.weight.data[:] = nn.Parameter(x.view(1, c1, 1, 1))
        self.c1 = c1

    def forward(self, x):
        """Applies a transformer layer on input tensor 'x' and returns a tensor."""
        b, c, a = x.shape  # batch, channels, anchors
        return self.conv(x.view(b, 4, self.c1, a).transpose(2, 1).softmax(1)).view(b, 4, a)
        # return self.conv(x.view(b, self.c1, 4, a).softmax(1)).view(b, 4, a)


class Proto(nn.Module):
    """YOLOv8 mask Proto module for segmentation models."""

    def __init__(self, c1, c_=256, c2=32):
        """
        Initializes the YOLOv8 mask Proto module with specified number of protos and masks.

        Input arguments are ch_in, number of protos, number of masks.
        """
        super().__init__()
        self.cv1 = Conv(c1, c_, k=3)
        self.upsample = nn.ConvTranspose2d(c_, c_, 2, 2, 0, bias=True)  # nn.Upsample(scale_factor=2, mode='nearest')
        self.cv2 = Conv(c_, c_, k=3)
        self.cv3 = Conv(c_, c2)

    def forward(self, x):
        """Performs a forward pass through layers using an upsampled input image."""
        return self.cv3(self.cv2(self.upsample(self.cv1(x))))


class HGStem(nn.Module):
    """
    StemBlock of PPHGNetV2 with 5 convolutions and one maxpool2d.

    https://github.com/PaddlePaddle/PaddleDetection/blob/develop/ppdet/modeling/backbones/hgnet_v2.py
    """

    def __init__(self, c1, cm, c2):
        """Initialize the SPP layer with input/output channels and specified kernel sizes for max pooling."""
        super().__init__()
        self.stem1 = Conv(c1, cm, 3, 2, act=nn.ReLU())
        self.stem2a = Conv(cm, cm // 2, 2, 1, 0, act=nn.ReLU())
        self.stem2b = Conv(cm // 2, cm, 2, 1, 0, act=nn.ReLU())
        self.stem3 = Conv(cm * 2, cm, 3, 2, act=nn.ReLU())
        self.stem4 = Conv(cm, c2, 1, 1, act=nn.ReLU())
        self.pool = nn.MaxPool2d(kernel_size=2, stride=1, padding=0, ceil_mode=True)

    def forward(self, x):
        """Forward pass of a PPHGNetV2 backbone layer."""
        x = self.stem1(x)
        x = F.pad(x, [0, 1, 0, 1])
        x2 = self.stem2a(x)
        x2 = F.pad(x2, [0, 1, 0, 1])
        x2 = self.stem2b(x2)
        x1 = self.pool(x)
        x = torch.cat([x1, x2], dim=1)
        x = self.stem3(x)
        x = self.stem4(x)
        return x


class HGBlock(nn.Module):
    """
    HG_Block of PPHGNetV2 with 2 convolutions and LightConv.

    https://github.com/PaddlePaddle/PaddleDetection/blob/develop/ppdet/modeling/backbones/hgnet_v2.py
    """

    def __init__(self, c1, cm, c2, k=3, n=6, lightconv=False, shortcut=False, act=nn.ReLU()):
        """Initializes a CSP Bottleneck with 1 convolution using specified input and output channels."""
        super().__init__()
        block = LightConv if lightconv else Conv
        self.m = nn.ModuleList(block(c1 if i == 0 else cm, cm, k=k, act=act) for i in range(n))
        self.sc = Conv(c1 + n * cm, c2 // 2, 1, 1, act=act)  # squeeze conv
        self.ec = Conv(c2 // 2, c2, 1, 1, act=act)  # excitation conv
        self.add = shortcut and c1 == c2

    def forward(self, x):
        """Forward pass of a PPHGNetV2 backbone layer."""
        y = [x]
        y.extend(m(y[-1]) for m in self.m)
        y = self.ec(self.sc(torch.cat(y, 1)))
        return y + x if self.add else y


class SPP(nn.Module):
    """Spatial Pyramid Pooling (SPP) layer https://arxiv.org/abs/1406.4729."""

    def __init__(self, c1, c2, k=(5, 9, 13)):
        """Initialize the SPP layer with input/output channels and pooling kernel sizes."""
        super().__init__()
        c_ = c1 // 2  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c_ * (len(k) + 1), c2, 1, 1)
        self.m = nn.ModuleList([nn.MaxPool2d(kernel_size=x, stride=1, padding=x // 2) for x in k])

    def forward(self, x):
        """Forward pass of the SPP layer, performing spatial pyramid pooling."""
        x = self.cv1(x)
        return self.cv2(torch.cat([x] + [m(x) for m in self.m], 1))


class SPPF(nn.Module):
    """Spatial Pyramid Pooling - Fast (SPPF) layer for YOLOv5 by Glenn Jocher."""

    def __init__(self, c1, c2, k=5):
        """
        Initializes the SPPF layer with given input/output channels and kernel size.

        This module is equivalent to SPP(k=(5, 9, 13)).
        """
        super().__init__()
        c_ = c1 // 2  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c_ * 4, c2, 1, 1)
        self.m = nn.MaxPool2d(kernel_size=k, stride=1, padding=k // 2)

    def forward(self, x):
        """Forward pass through Ghost Convolution block."""
        x = self.cv1(x)
        y1 = self.m(x)
        y2 = self.m(y1)
        return self.cv2(torch.cat((x, y1, y2, self.m(y2)), 1))


class C1(nn.Module):
    """CSP Bottleneck with 1 convolution."""

    def __init__(self, c1, c2, n=1):
        """Initializes the CSP Bottleneck with configurations for 1 convolution with arguments ch_in, ch_out, number."""
        super().__init__()
        self.cv1 = Conv(c1, c2, 1, 1)
        self.m = nn.Sequential(*(Conv(c2, c2, 3) for _ in range(n)))

    def forward(self, x):
        """Applies cross-convolutions to input in the C3 module."""
        y = self.cv1(x)
        return self.m(y) + y


class C2(nn.Module):
    """CSP Bottleneck with 2 convolutions."""

    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):
        """Initializes the CSP Bottleneck with 2 convolutions module with arguments ch_in, ch_out, number, shortcut,
        groups, expansion.
        """
        super().__init__()
        self.c = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, 2 * self.c, 1, 1)
        self.cv2 = Conv(2 * self.c, c2, 1)  # optional act=FReLU(c2)
        # self.attention = ChannelAttention(2 * self.c)  # or SpatialAttention()
        self.m = nn.Sequential(*(Bottleneck(self.c, self.c, shortcut, g, k=((3, 3), (3, 3)), e=1.0) for _ in range(n)))

    def forward(self, x):
        """Forward pass through the CSP bottleneck with 2 convolutions."""
        a, b = self.cv1(x).chunk(2, 1)
        return self.cv2(torch.cat((self.m(a), b), 1))


class C2f(nn.Module):
    """Faster Implementation of CSP Bottleneck with 2 convolutions."""

    def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5):
        """Initialize CSP bottleneck layer with two convolutions with arguments ch_in, ch_out, number, shortcut, groups,
        expansion.
        """
        super().__init__()
        self.c = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, 2 * self.c, 1, 1)
        self.cv2 = Conv((2 + n) * self.c, c2, 1)  # optional act=FReLU(c2)
        self.m = nn.ModuleList(Bottleneck(self.c, self.c, shortcut, g, k=((3, 3), (3, 3)), e=1.0) for _ in range(n))

    def forward(self, x):
        """Forward pass through C2f layer."""
        y = list(self.cv1(x).chunk(2, 1))
        y.extend(m(y[-1]) for m in self.m)
        return self.cv2(torch.cat(y, 1))

    def forward_split(self, x):
        """Forward pass using split() instead of chunk()."""
        y = list(self.cv1(x).split((self.c, self.c), 1))
        y.extend(m(y[-1]) for m in self.m)
        return self.cv2(torch.cat(y, 1))


class C3(nn.Module):
    """CSP Bottleneck with 3 convolutions."""

    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):
        """Initialize the CSP Bottleneck with given channels, number, shortcut, groups, and expansion values."""
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c1, c_, 1, 1)
        self.cv3 = Conv(2 * c_, c2, 1)  # optional act=FReLU(c2)
        self.m = nn.Sequential(*(Bottleneck(c_, c_, shortcut, g, k=((1, 1), (3, 3)), e=1.0) for _ in range(n)))

    def forward(self, x):
        """Forward pass through the CSP bottleneck with 2 convolutions."""
        return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), 1))


class C3x(C3):
    """C3 module with cross-convolutions."""

    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):
        """Initialize C3TR instance and set default parameters."""
        super().__init__(c1, c2, n, shortcut, g, e)
        self.c_ = int(c2 * e)
        self.m = nn.Sequential(*(Bottleneck(self.c_, self.c_, shortcut, g, k=((1, 3), (3, 1)), e=1) for _ in range(n)))


class RepC3(nn.Module):
    """Rep C3."""

    def __init__(self, c1, c2, n=3, e=1.0):
        """Initialize CSP Bottleneck with a single convolution using input channels, output channels, and number."""
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c1, c_, 1, 1)
        self.m = nn.Sequential(*[RepConv(c_, c_) for _ in range(n)])
        self.cv3 = Conv(c_, c2, 1, 1) if c_ != c2 else nn.Identity()

    def forward(self, x):
        """Forward pass of RT-DETR neck layer."""
        return self.cv3(self.m(self.cv1(x)) + self.cv2(x))


class C3TR(C3):
    """C3 module with TransformerBlock()."""

    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):
        """Initialize C3Ghost module with GhostBottleneck()."""
        super().__init__(c1, c2, n, shortcut, g, e)
        c_ = int(c2 * e)
        self.m = TransformerBlock(c_, c_, 4, n)


class C3Ghost(C3):
    """C3 module with GhostBottleneck()."""

    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):
        """Initialize 'SPP' module with various pooling sizes for spatial pyramid pooling."""
        super().__init__(c1, c2, n, shortcut, g, e)
        c_ = int(c2 * e)  # hidden channels
        self.m = nn.Sequential(*(GhostBottleneck(c_, c_) for _ in range(n)))


class GhostBottleneck(nn.Module):
    """Ghost Bottleneck https://github.com/huawei-noah/ghostnet."""

    def __init__(self, c1, c2, k=3, s=1):
        """Initializes GhostBottleneck module with arguments ch_in, ch_out, kernel, stride."""
        super().__init__()
        c_ = c2 // 2
        self.conv = nn.Sequential(
            GhostConv(c1, c_, 1, 1),  # pw
            DWConv(c_, c_, k, s, act=False) if s == 2 else nn.Identity(),  # dw
            GhostConv(c_, c2, 1, 1, act=False))  # pw-linear
        self.shortcut = nn.Sequential(DWConv(c1, c1, k, s, act=False), Conv(c1, c2, 1, 1,
                                                                            act=False)) if s == 2 else nn.Identity()

    def forward(self, x):
        """Applies skip connection and concatenation to input tensor."""
        return self.conv(x) + self.shortcut(x)


class Bottleneck(nn.Module):
    """Standard bottleneck."""

    def __init__(self, c1, c2, shortcut=True, g=1, k=(3, 3), e=0.5):
        """Initializes a bottleneck module with given input/output channels, shortcut option, group, kernels, and
        expansion.
        """
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, k[0], 1)
        self.cv2 = Conv(c_, c2, k[1], 1, g=g)
        self.add = shortcut and c1 == c2

    def forward(self, x):
        """'forward()' applies the YOLO FPN to input data."""
        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))


class BottleneckCSP(nn.Module):
    """CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks."""

    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):
        """Initializes the CSP Bottleneck given arguments for ch_in, ch_out, number, shortcut, groups, expansion."""
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = nn.Conv2d(c1, c_, 1, 1, bias=False)
        self.cv3 = nn.Conv2d(c_, c_, 1, 1, bias=False)
        self.cv4 = Conv(2 * c_, c2, 1, 1)
        self.bn = nn.BatchNorm2d(2 * c_)  # applied to cat(cv2, cv3)
        self.act = nn.SiLU()
        self.m = nn.Sequential(*(Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)))

    def forward(self, x):
        """Applies a CSP bottleneck with 3 convolutions."""
        y1 = self.cv3(self.m(self.cv1(x)))
        y2 = self.cv2(x)
        return self.cv4(self.act(self.bn(torch.cat((y1, y2), 1))))

################################### RT-DETR PResnet ###################################
def get_activation(act: str, inpace: bool=True):
    '''get activation
    '''
    act = act.lower()
    
    if act == 'silu':
        m = nn.SiLU()

    elif act == 'relu':
        m = nn.ReLU()

    elif act == 'leaky_relu':
        m = nn.LeakyReLU()

    elif act == 'silu':
        m = nn.SiLU()
    
    elif act == 'gelu':
        m = nn.GELU()
        
    elif act is None:
        m = nn.Identity()
    
    elif isinstance(act, nn.Module):
        m = act

    else:
        raise RuntimeError('')  

    if hasattr(m, 'inplace'):
        m.inplace = inpace
    
    return m 

class ConvNormLayer(nn.Module):
    def __init__(self, ch_in, ch_out, kernel_size, stride, padding=None, bias=False, act=None):
        super().__init__()
        self.conv = nn.Conv2d(
            ch_in, 
            ch_out, 
            kernel_size, 
            stride, 
            padding=(kernel_size-1)//2 if padding is None else padding, 
            bias=bias)
        self.norm = nn.BatchNorm2d(ch_out)
        self.act = nn.Identity() if act is None else get_activation(act) 

    def forward(self, x):
        return self.act(self.norm(self.conv(x)))
    
    def forward_fuse(self, x):
        """Perform transposed convolution of 2D data."""
        return self.act(self.conv(x))

class BasicBlock(nn.Module):
    expansion = 1

    def __init__(self, ch_in, ch_out, stride, shortcut, act='relu', variant='d'):
        super().__init__()

        self.shortcut = shortcut

        if not shortcut:
            if variant == 'd' and stride == 2:
                self.short = nn.Sequential(OrderedDict([
                    ('pool', nn.AvgPool2d(2, 2, 0, ceil_mode=True)),
                    ('conv', ConvNormLayer(ch_in, ch_out, 1, 1))
                ]))
            else:
                self.short = ConvNormLayer(ch_in, ch_out, 1, stride)

        self.branch2a = ConvNormLayer(ch_in, ch_out, 3, stride, act=act)
        self.branch2b = ConvNormLayer(ch_out, ch_out, 3, 1, act=None)
        self.act = nn.Identity() if act is None else get_activation(act) 


    def forward(self, x):
        out = self.branch2a(x)
        out = self.branch2b(out)
        if self.shortcut:
            short = x
        else:
            short = self.short(x)
        
        out = out + short
        out = self.act(out)

        return out


class BottleNeck(nn.Module):
    expansion = 4

    def __init__(self, ch_in, ch_out, stride, shortcut, act='relu', variant='d'):
        super().__init__()

        if variant == 'a':
            stride1, stride2 = stride, 1
        else:
            stride1, stride2 = 1, stride

        width = ch_out 

        self.branch2a = ConvNormLayer(ch_in, width, 1, stride1, act=act)
        self.branch2b = ConvNormLayer(width, width, 3, stride2, act=act)
        self.branch2c = ConvNormLayer(width, ch_out * self.expansion, 1, 1)

        self.shortcut = shortcut
        if not shortcut:
            if variant == 'd' and stride == 2:
                self.short = nn.Sequential(OrderedDict([
                    ('pool', nn.AvgPool2d(2, 2, 0, ceil_mode=True)),
                    ('conv', ConvNormLayer(ch_in, ch_out * self.expansion, 1, 1))
                ]))
            else:
                self.short = ConvNormLayer(ch_in, ch_out * self.expansion, 1, stride)

        self.act = nn.Identity() if act is None else get_activation(act) 

    def forward(self, x):
        out = self.branch2a(x)
        out = self.branch2b(out)
        out = self.branch2c(out)

        if self.shortcut:
            short = x
        else:
            short = self.short(x)

        out = out + short
        out = self.act(out)

        return out


class Blocks(nn.Module):
    def __init__(self, ch_in, ch_out, block, count, stage_num, act='relu', input_resolution=None, sr_ratio=None, kernel_size=None, kan_name=None, variant='d'):
        super().__init__()

        self.blocks = nn.ModuleList()
        for i in range(count):
            if input_resolution is not None and sr_ratio is not None:
                self.blocks.append(
                    block(
                        ch_in, 
                        ch_out,
                        stride=2 if i == 0 and stage_num != 2 else 1, 
                        shortcut=False if i == 0 else True,
                        variant=variant,
                        act=act,
                        input_resolution=input_resolution,
                        sr_ratio=sr_ratio)
                )
            elif kernel_size is not None:
                self.blocks.append(
                    block(
                        ch_in, 
                        ch_out,
                        stride=2 if i == 0 and stage_num != 2 else 1, 
                        shortcut=False if i == 0 else True,
                        variant=variant,
                        act=act,
                        kernel_size=kernel_size)
                )
            elif kan_name is not None:
                self.blocks.append(
                    block(
                        ch_in, 
                        ch_out,
                        stride=2 if i == 0 and stage_num != 2 else 1, 
                        shortcut=False if i == 0 else True,
                        variant=variant,
                        act=act,
                        kan_name=kan_name)
                )
            else:
                self.blocks.append(
                    block(
                        ch_in, 
                        ch_out,
                        stride=2 if i == 0 and stage_num != 2 else 1, 
                        shortcut=False if i == 0 else True,
                        variant=variant,
                        act=act)
                )
            if i == 0:
                ch_in = ch_out * block.expansion

    def forward(self, x):
        out = x
        for block in self.blocks:
            out = block(out)
        return out
import math
import torch
import torch.nn as nn
import torch.nn.functional as F


# ==================== åŸºç¡€ç»„ä»¶ ====================

class MPCA(nn.Module):
    """Multi-scale Progressive Channel Attention"""
    def __init__(self, c1, c2, gamma=2, bias=1):
        super().__init__()
        self.c1, self.c2 = c1, c2
        self.avg1 = nn.AdaptiveAvgPool2d(1)
        self.avg2 = nn.AdaptiveAvgPool2d(1)

        def k(c): 
            ks = int(abs((math.log(c, 2) + bias) / gamma))
            return ks if ks % 2 else ks + 1

        self.conv1 = nn.Conv1d(1, 1, k(c1), padding=k(c1)//2, bias=False)
        self.conv2 = nn.Conv1d(1, 1, k(c2), padding=k(c2)//2, bias=False)
        self.conv3 = nn.Conv1d(1, 1, k(c1+c2), padding=k(c1+c2)//2, bias=False)
        self.sigmoid = nn.Sigmoid()
        self.up = nn.ConvTranspose2d(c2, c1, 2, 2)

    def forward(self, x1, x2):
        b = x1.shape[0]
        x1_w = self.conv1(self.avg1(x1).view(b, 1, -1)).view(b, self.c1, 1, 1)
        x2_w = self.conv2(self.avg2(x2).view(b, 1, -1)).view(b, self.c2, 1, 1)
        w = torch.cat([x1_w, x2_w], dim=1)
        w = self.sigmoid(self.conv3(w.view(b, 1, -1)).view(b, self.c1+self.c2, 1, 1))
        w1, w2 = torch.split(w, [self.c1, self.c2], dim=1)
        return x1 * w1 + self.up(x2 * w2)


class SpatialAttention(nn.Module):
    """Spatial Attention"""
    def __init__(self, kernel_size=7):
        super().__init__()
        self.conv = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg = x.mean(1, keepdim=True)
        maxv, _ = x.max(1, keepdim=True)
        return x * self.sigmoid(self.conv(torch.cat([avg, maxv], 1)))


# ==================== æ–¹æ¡ˆ1: è½»é‡çº§ ====================

class MPCA_Spatial(nn.Module):
    """è½»é‡çº§èåˆ - å¿«é€ŸéªŒè¯"""
    def __init__(self, c1, c2):
        super().__init__()
        self.mpca = MPCA(c1, c2)
        self.spatial = SpatialAttention()
        self.out = nn.Conv2d(c1, c1, 1)

    def forward(self, x_high, x_low):
        x = self.mpca(x_high, x_low)
        x = self.spatial(x)
        return self.out(x)


# ==================== æ–¹æ¡ˆ2: å¹³è¡¡æ–¹æ¡ˆ ====================

class FCSF_Lightweight(nn.Module):
    """å¹³è¡¡çš„é¢‘ç‡æ„ŸçŸ¥è·¨å°ºåº¦èåˆ"""
    def __init__(self, c1, c2):
        super().__init__()
        self.mpca = MPCA(c1, c2)
        self.spatial = SpatialAttention()
        self.channel_attn = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(c1, c1 // 4, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(c1 // 4, c1, 1),
            nn.Sigmoid()
        )
        self.align = nn.Conv2d(c1, c1, 1)

    def forward(self, x_high, x_low):
        x_c = self.mpca(x_high, x_low)
        x_f = self.spatial(x_high)
        x_f = x_f * self.channel_attn(x_f)
        return self.align(x_c + x_f)


# ==================== æ–¹æ¡ˆ3: æœ€ä½³æ€§èƒ½ ====================
class GatedFusion(nn.Module):
    """
    é—¨æ§äº¤äº’èåˆæ¨¡å— - YAMLé…ç½®å…¼å®¹ç‰ˆæœ¬
    
    åŸºäºGatedInteractiveFusion_ResNet18ï¼Œä¸“ä¸ºé¥æ„Ÿå›¾åƒå°ç›®æ ‡æ£€æµ‹ä¼˜åŒ–
    
    ç”¨æ³•ï¼ˆåœ¨YAMLé…ç½®æ–‡ä»¶ä¸­ï¼‰:
        # åŸºç¡€ç”¨æ³•
        - [-1, 1, GatedFusion, [256]]  
        
        # å¸¦é‡å¤ï¼ˆn>1ä¼šå †å å¤šä¸ªGatedFusionï¼‰
        - [-1, 2, GatedFusion, [256]]  
        
    å‚æ•°è¯´æ˜:
        c1: è¾“å…¥é€šé“æ•°ï¼ˆConcatåçš„é€šé“ï¼‰
        c2: è¾“å‡ºé€šé“æ•°ï¼ˆé€šå¸¸256ï¼‰
        n: é‡å¤æ¬¡æ•°ï¼ˆå»ºè®®1ï¼Œå¤šäº†ä¼šå¢åŠ è®¡ç®—é‡ï¼‰
        wt_type: å°æ³¢ç±»å‹ 'haar'(æœ€å¿«) | 'db1'(å¹³è¡¡)
        num_heads: æ³¨æ„åŠ›å¤´æ•°ï¼ˆResNet18ç”¨4ï¼‰
        e: expansionï¼ˆå…¼å®¹RepC3å‚æ•°ï¼Œä½†GatedFusionå†…éƒ¨ä¸ä½¿ç”¨ï¼‰
    
    ç‰¹ç‚¹:
        - Haarå°æ³¢å¿«é€Ÿåˆ†è§£ï¼ˆæ— éœ€pywtåº“ï¼‰
        - å°æ³¢-å¯¹æ¯”åŒå‘é—¨æ§
        - é¢‘åŸŸ+ç©ºåŸŸè”åˆå¤„ç†
        - é€‚åˆé¥æ„Ÿå°ç›®æ ‡æ£€æµ‹
    
    æ€§èƒ½:
        - APsæå‡: +3.5~4.5%
        - æ¨ç†å¢åŠ : +2~3ms
        - å‚æ•°å¢åŠ : çº¦+15%
    """
    
    def __init__(self, c1, c2, n=1, wt_type='haar', num_heads=4, e=0.5):
        super().__init__()
        
        # è¾“å…¥é€šé“å¯¹é½ï¼ˆå¦‚æœConcatåé€šé“æ•°!=c2ï¼‰
        if c1 != c2:
            self.input_proj = ConvNormLayer(c1, c2, 1, 1, act='silu')
        else:
            self.input_proj = nn.Identity()
        
        # æ ¸å¿ƒé—¨æ§èåˆæ¨¡å—
        self.gated_fusion = GatedInteractiveFusion_ResNet18(
            channels=c2,
            wt_type=wt_type,
            num_heads=num_heads
        )
        
        # å¦‚æœn>1ï¼Œå †å å¤šä¸ªèåˆå—
        if n > 1:
            self.extra_blocks = nn.ModuleList([
                GatedInteractiveFusion_ResNet18(
                    channels=c2,
                    wt_type=wt_type,
                    num_heads=num_heads
                ) for _ in range(n - 1)
            ])
        else:
            self.extra_blocks = None
    
    def forward(self, x):
        """
        å‰å‘ä¼ æ’­
        
        Args:
            x: è¾“å…¥ç‰¹å¾ [B, C1, H, W]
        
        Returns:
            è¾“å‡ºç‰¹å¾ [B, C2, H, W]
        """
        # é€šé“å¯¹é½
        x = self.input_proj(x)
        
        # ä¸»èåˆå—
        x = self.gated_fusion(x)
        
        # é¢å¤–çš„èåˆå—ï¼ˆå¦‚æœn>1ï¼‰
        if self.extra_blocks is not None:
            for block in self.extra_blocks:
                x = block(x)
        
        return x


class GatedInteractiveFusion_ResNet18(nn.Module):
    """
    é—¨æ§äº¤äº’èåˆ - ResNet18ä¼˜åŒ–ç‰ˆ
    
    æ ¸å¿ƒåˆ›æ–°:
    1. å¿«é€ŸHaarå°æ³¢å˜æ¢ï¼ˆæ— éœ€pywtåº“ï¼‰
    2. å¯¹æ¯”ç‰¹å¾â†’å°æ³¢å­å¸¦é—¨æ§
    3. å°æ³¢ç‰¹å¾â†’å¯¹æ¯”ç©ºé—´é—¨æ§
    4. å…¨å±€è‡ªé€‚åº”èåˆæƒé‡
    
    å·¥ä½œæµç¨‹:
    è¾“å…¥x â†’ å°æ³¢åˆ†è§£(LL/LH/HL/HH) â†’ é—¨æ§å¢å¼º
          â†˜ å¯¹æ¯”ç‰¹å¾æå– â†’ ç©ºé—´é—¨æ§ â†—
                      â†“
                å…¨å±€èåˆ + æ®‹å·®è¿æ¥
    """
    
    def __init__(self, channels, wt_type='haar', num_heads=4):
        super().__init__()
        
        self.channels = channels
        self.use_simple_wavelet = (wt_type == 'haar')
        
        # å¦‚æœç”¨æ ‡å‡†å°æ³¢ï¼ˆdb1ç­‰ï¼‰ï¼Œéœ€è¦åˆ›å»ºæ»¤æ³¢å™¨
        if not self.use_simple_wavelet:
            try:
                import pywt
                w = pywt.Wavelet(wt_type)
                
                # åˆ†è§£æ»¤æ³¢å™¨
                dec_hi = torch.tensor(w.dec_hi[::-1], dtype=torch.float)
                dec_lo = torch.tensor(w.dec_lo[::-1], dtype=torch.float)
                dec_filters = torch.stack([
                    dec_lo.unsqueeze(0) * dec_lo.unsqueeze(1),  # LL
                    dec_lo.unsqueeze(0) * dec_hi.unsqueeze(1),  # LH
                    dec_hi.unsqueeze(0) * dec_lo.unsqueeze(1),  # HL
                    dec_hi.unsqueeze(0) * dec_hi.unsqueeze(1)   # HH
                ], dim=0)
                self.wt_filter = nn.Parameter(
                    dec_filters[:, None].repeat(channels, 1, 1, 1),
                    requires_grad=False
                )
                
                # é‡å»ºæ»¤æ³¢å™¨
                rec_hi = torch.tensor(w.rec_hi, dtype=torch.float)
                rec_lo = torch.tensor(w.rec_lo, dtype=torch.float)
                rec_filters = torch.stack([
                    rec_lo.unsqueeze(0) * rec_lo.unsqueeze(1),
                    rec_lo.unsqueeze(0) * rec_hi.unsqueeze(1),
                    rec_hi.unsqueeze(0) * rec_lo.unsqueeze(1),
                    rec_hi.unsqueeze(0) * rec_hi.unsqueeze(1)
                ], dim=0)
                self.iwt_filter = nn.Parameter(
                    rec_filters[:, None].repeat(channels, 1, 1, 1),
                    requires_grad=False
                )
            except ImportError:
                print("Warning: pywt not found, fallback to haar")
                self.use_simple_wavelet = True
        
        # å°æ³¢åŸŸå¤„ç†ï¼ˆå¤„ç†4ä¸ªå­å¸¦ï¼‰
        self.wt_process = nn.Sequential(
            nn.Conv2d(channels * 4, channels * 4, 3, padding=1, 
                     groups=channels, bias=False),  # æ·±åº¦å·ç§¯
            nn.BatchNorm2d(channels * 4),
            nn.SiLU()
        )
        
        # å¯¹æ¯”ç‰¹å¾æå–
        self.contrast_extract = nn.Sequential(
            nn.Conv2d(channels, channels, 3, padding=1, 
                     groups=channels, bias=False),  # æ·±åº¦å·ç§¯
            nn.BatchNorm2d(channels),
            nn.SiLU(),
            nn.Conv2d(channels, channels, 1, bias=False),  # ç‚¹å·ç§¯
            nn.BatchNorm2d(channels)
        )
        
        # é—¨æ§ç½‘ç»œ1: å¯¹æ¯” â†’ å°æ³¢å­å¸¦é—¨æ§
        # è¾“å‡º[B, 4, 1, 1]æ§åˆ¶4ä¸ªå°æ³¢å­å¸¦çš„æƒé‡
        self.contrast2wt_gate = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(channels, 4, 1),
            nn.Sigmoid()
        )
        
        # é—¨æ§ç½‘ç»œ2: å°æ³¢ â†’ å¯¹æ¯”ç©ºé—´é—¨æ§
        # è¾“å‡º[B, C, 1, 1]æˆ–[B, C, H, W]æ§åˆ¶å¯¹æ¯”ç‰¹å¾çš„ç©ºé—´æƒé‡
        self.wt2contrast_gate = nn.Sequential(
            nn.Conv2d(channels, channels // 4, 1),
            nn.BatchNorm2d(channels // 4),
            nn.SiLU(),
            nn.Conv2d(channels // 4, channels, 1),
            nn.Sigmoid()
        )
        
        # å…¨å±€èåˆé—¨æ§: å­¦ä¹ å°æ³¢å’Œå¯¹æ¯”ç‰¹å¾çš„æœ€ä¼˜æ··åˆæ¯”ä¾‹
        self.global_gate = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(channels * 2, 2, 1),
            nn.Softmax(dim=1)
        )
        
        # è¾“å‡ºç²¾ç‚¼
        self.refine = nn.Sequential(
            nn.Conv2d(channels, channels, 3, padding=1, bias=False),
            nn.BatchNorm2d(channels),
            nn.SiLU(),
            nn.Conv2d(channels, channels, 1, bias=False),
            nn.BatchNorm2d(channels)
        )
    
    def simple_haar_wavelet(self, x):
        """
        å¿«é€ŸHaarå°æ³¢å˜æ¢ï¼ˆæ— éœ€pywtåº“ï¼‰
        
        Haarå°æ³¢ = ç®€å•çš„å¹³å‡å’Œå·®åˆ†:
        - LL (ä½é¢‘): (x00 + x01 + x10 + x11) / 2
        - LH (æ°´å¹³é«˜é¢‘): (x00 + x01 - x10 - x11) / 2
        - HL (å‚ç›´é«˜é¢‘): (x00 - x01 + x10 - x11) / 2
        - HH (å¯¹è§’é«˜é¢‘): (x00 - x01 - x10 + x11) / 2
        
        Args:
            x: [B, C, H, W]
        
        Returns:
            [B, C, 4, H/2, W/2] - 4ä¸ªå­å¸¦
        """
        B, C, H, W = x.shape
        
        # 2x2å—çš„4ä¸ªä½ç½®
        x_00 = x[:, :, 0::2, 0::2]  # å·¦ä¸Š
        x_01 = x[:, :, 0::2, 1::2]  # å³ä¸Š
        x_10 = x[:, :, 1::2, 0::2]  # å·¦ä¸‹
        x_11 = x[:, :, 1::2, 1::2]  # å³ä¸‹
        
        # è®¡ç®—4ä¸ªå­å¸¦
        x_ll = (x_00 + x_01 + x_10 + x_11) / 2  # ä½é¢‘ï¼ˆè¿‘ä¼¼ï¼‰
        x_lh = (x_00 + x_01 - x_10 - x_11) / 2  # æ°´å¹³ç»†èŠ‚
        x_hl = (x_00 - x_01 + x_10 - x_11) / 2  # å‚ç›´ç»†èŠ‚
        x_hh = (x_00 - x_01 - x_10 + x_11) / 2  # å¯¹è§’ç»†èŠ‚
        
        return torch.stack([x_ll, x_lh, x_hl, x_hh], dim=2)
    
    def simple_haar_inverse(self, x_wt):
        """
        å¿«é€ŸHaaré€†å˜æ¢
        
        Args:
            x_wt: [B, C, 4, H/2, W/2]
        
        Returns:
            [B, C, H, W]
        """
        x_ll, x_lh, x_hl, x_hh = x_wt[:, :, 0], x_wt[:, :, 1], x_wt[:, :, 2], x_wt[:, :, 3]
        
        # é‡å»º4ä¸ªä½ç½®
        x_00 = x_ll + x_lh + x_hl + x_hh
        x_01 = x_ll + x_lh - x_hl - x_hh
        x_10 = x_ll - x_lh + x_hl - x_hh
        x_11 = x_ll - x_lh - x_hl + x_hh
        
        # æ‹¼æ¥å›åŸå§‹åˆ†è¾¨ç‡
        B, C, H, W = x_ll.shape
        x_recon = torch.zeros(B, C, H*2, W*2, device=x_ll.device, dtype=x_ll.dtype)
        x_recon[:, :, 0::2, 0::2] = x_00
        x_recon[:, :, 0::2, 1::2] = x_01
        x_recon[:, :, 1::2, 0::2] = x_10
        x_recon[:, :, 1::2, 1::2] = x_11
        
        return x_recon / 2
    
    def forward(self, x):
        """
        å‰å‘ä¼ æ’­
        
        Args:
            x: [B, C, H, W]
        
        Returns:
            [B, C, H, W]
        """
        B, C, H, W = x.shape
        
        # å¤„ç†å¥‡æ•°å°ºå¯¸ï¼ˆå°æ³¢å˜æ¢éœ€è¦å¶æ•°ï¼‰
        pad_h = H % 2
        pad_w = W % 2
        if pad_h or pad_w:
            x_padded = F.pad(x, (0, pad_w, 0, pad_h))
        else:
            x_padded = x
        
        # ========== å°æ³¢åˆ†æ”¯ ==========
        if self.use_simple_wavelet:
            # å¿«é€ŸHaarå˜æ¢
            x_wt = self.simple_haar_wavelet(x_padded)
        else:
            # æ ‡å‡†å°æ³¢å˜æ¢ï¼ˆdb1ç­‰ï¼‰
            x_wt = F.conv2d(x_padded, self.wt_filter, stride=2, 
                           groups=C, padding=self.wt_filter.shape[2]//2-1)
            x_wt = x_wt.reshape(B, C, 4, x_wt.shape[-2], x_wt.shape[-1])
        
        # å°æ³¢åŸŸå¤„ç†
        B_wt, C_wt, _, H_wt, W_wt = x_wt.shape
        x_wt_flat = x_wt.reshape(B, C * 4, H_wt, W_wt)
        x_wt_processed = self.wt_process(x_wt_flat)
        
        # ========== å¯¹æ¯”åˆ†æ”¯ ==========
        x_contrast = self.contrast_extract(x)
        
        # ========== é—¨æ§äº¤äº’ ==========
        # 1. å¯¹æ¯” â†’ å°æ³¢å­å¸¦é—¨æ§
        # å¯¹æ¯”ç‰¹å¾ç”Ÿæˆ4ä¸ªæƒé‡ï¼Œæ§åˆ¶LL/LH/HL/HHçš„é‡è¦æ€§
        subband_gates = self.contrast2wt_gate(x_contrast)  # [B, 4, 1, 1]
        subband_gates = subband_gates.unsqueeze(2).expand(B, C, 4, 1, 1)
        
        x_wt_reshaped = x_wt_processed.reshape(B, C, 4, H_wt, W_wt)
        x_wt_gated = x_wt_reshaped * subband_gates
        
        # é€†å˜æ¢å›ç©ºé—´åŸŸ
        if self.use_simple_wavelet:
            x_wt_recon = self.simple_haar_inverse(x_wt_gated)
        else:
            x_wt_gated_flat = x_wt_gated.reshape(B, C * 4, H_wt, W_wt)
            x_wt_recon = F.conv_transpose2d(
                x_wt_gated_flat, self.iwt_filter, stride=2,
                groups=C, padding=self.iwt_filter.shape[2]//2-1
            )
        
        # å»é™¤padding
        x_wt_recon = x_wt_recon[:, :, :H, :W]
        
        # 2. å°æ³¢ â†’ å¯¹æ¯”ç©ºé—´é—¨æ§
        # å°æ³¢é‡å»ºç‰¹å¾ç”Ÿæˆç©ºé—´æƒé‡ï¼Œæ§åˆ¶å¯¹æ¯”ç‰¹å¾çš„æ¿€æ´»ä½ç½®
        contrast_gate = self.wt2contrast_gate(x_wt_recon)
        x_contrast_gated = x_contrast * contrast_gate
        
        # ========== å…¨å±€èåˆ ==========
        # å­¦ä¹ ä¸¤ä¸ªåˆ†æ”¯çš„æœ€ä¼˜æ··åˆæ¯”ä¾‹
        fusion_input = torch.cat([x_wt_recon, x_contrast_gated], dim=1)
        global_weights = self.global_gate(fusion_input)  # [B, 2, 1, 1]
        
        x_fused = (global_weights[:, 0:1] * x_wt_recon + 
                   global_weights[:, 1:2] * x_contrast_gated)
        
        # ç²¾ç‚¼å’Œæ®‹å·®è¿æ¥
        out = self.refine(x_fused)
        out = out + x  # æ®‹å·®è¿æ¥ï¼Œä¿æŒæ¢¯åº¦æµåŠ¨
        
        return out

class ConvNormLayer(nn.Module):
    """åŸºç¡€å·ç§¯-å½’ä¸€åŒ–å±‚"""
    def __init__(self, ch_in, ch_out, kernel_size, stride, padding=None, bias=False, act='silu'):
        super().__init__()
        if padding is None:
            padding = (kernel_size - 1) // 2
        self.conv = nn.Conv2d(ch_in, ch_out, kernel_size, stride, padding, bias=bias)
        self.norm = nn.BatchNorm2d(ch_out)
        if act == 'silu':
            self.act = nn.SiLU(inplace=True)
        elif act == 'relu':
            self.act = nn.ReLU(inplace=True)
        else:
            self.act = nn.Identity()

    def forward(self, x):
        return self.act(self.norm(self.conv(x)))

class DepthwiseSeparableConv(nn.Module):
    """æ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼ˆå¤§å¹…å‡å°‘å‚æ•°ï¼‰"""
    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):
        super().__init__()
        # æ·±åº¦å·ç§¯ï¼ˆæ¯ä¸ªé€šé“ç‹¬ç«‹å·ç§¯ï¼‰
        self.depthwise = nn.Conv2d(
            in_channels, in_channels, 
            kernel_size=kernel_size, 
            stride=stride, 
            padding=padding, 
            groups=in_channels,  # å…³é”®ï¼šgroups=in_channels
            bias=False
        )
        self.bn1 = nn.BatchNorm2d(in_channels)
        
        # ç‚¹å·ç§¯ï¼ˆ1x1å·ç§¯æ··åˆé€šé“ï¼‰
        self.pointwise = nn.Conv2d(in_channels, out_channels, 1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)
        self.act = nn.SiLU(inplace=True)

    def forward(self, x):
        x = self.depthwise(x)
        x = self.bn1(x)
        x = self.act(x)
        x = self.pointwise(x)
        x = self.bn2(x)
        return self.act(x)


# ============================================================================
# ç‰ˆæœ¬1: GatedFusion_Liteï¼ˆè½»åº¦ä¼˜åŒ–ï¼Œå‚æ•°å‡å°‘30%ï¼‰
# ============================================================================

class GatedFusion_Lite(nn.Module):
    """
    è½»åº¦ä¼˜åŒ–ç‰ˆæœ¬ - å‚æ•°å‡å°‘çº¦30%
    
    ä¼˜åŒ–ç­–ç•¥ï¼š
    1. ä½¿ç”¨æ·±åº¦å¯åˆ†ç¦»å·ç§¯æ›¿ä»£éƒ¨åˆ†æ ‡å‡†å·ç§¯
    2. å‡å°‘ç²¾ç‚¼æ¨¡å—çš„å¤æ‚åº¦
    3. ç®€åŒ–é—¨æ§ç½‘ç»œ
    
    æ€§èƒ½é¢„æœŸï¼š
    - å‚æ•°é‡ï¼šåŸç‰ˆ100% â†’ 70%
    - APsæå‡ï¼š+3.5% â†’ +3.0%
    - æ¨ç†é€Ÿåº¦ï¼šæ›´å¿«çº¦15%
    
    é€‚ç”¨åœºæ™¯ï¼š
    - ä¸­ç­‰è®¡ç®—èµ„æº
    - éœ€è¦å¹³è¡¡æ€§èƒ½å’Œæ•ˆç‡
    - æ¨èä½œä¸ºé»˜è®¤é€‰æ‹©
    """
    
    def __init__(self, c1, c2, n=1, wt_type='haar', num_heads=4, e=0.5):
        super().__init__()
        
        # è¾“å…¥å¯¹é½
        if c1 != c2:
            self.input_proj = ConvNormLayer(c1, c2, 1, 1, act='silu')
        else:
            self.input_proj = nn.Identity()
        
        # æ ¸å¿ƒèåˆ
        self.gated_fusion = GatedInteractiveFusion_Lite(c2, wt_type, num_heads)
        
        # å¤šå±‚å †å ï¼ˆå¦‚æœn>1ï¼‰
        if n > 1:
            self.extra_blocks = nn.ModuleList([
                GatedInteractiveFusion_Lite(c2, wt_type, num_heads)
                for _ in range(n - 1)
            ])
        else:
            self.extra_blocks = None
    
    def forward(self, x):
        x = self.input_proj(x)
        x = self.gated_fusion(x)
        if self.extra_blocks:
            for block in self.extra_blocks:
                x = block(x)
        return x


class GatedInteractiveFusion_Lite(nn.Module):
    """è½»åº¦ä¼˜åŒ–çš„é—¨æ§äº¤äº’èåˆ"""
    
    def __init__(self, channels, wt_type='haar', num_heads=4):
        super().__init__()
        self.channels = channels
        self.use_simple_wavelet = (wt_type == 'haar')
        
        # ========== ä¼˜åŒ–1: å°æ³¢å¤„ç†ç”¨æ·±åº¦å¯åˆ†ç¦»å·ç§¯ ==========
        self.wt_process = nn.Sequential(
            # æ·±åº¦å·ç§¯ï¼ˆå‚æ•°ï¼šC*4 * 9ï¼‰
            nn.Conv2d(channels * 4, channels * 4, 3, padding=1, 
                     groups=channels * 4, bias=False),
            nn.BatchNorm2d(channels * 4),
            nn.SiLU(inplace=True),
            # ç‚¹å·ç§¯é™ç»´ï¼ˆå‚æ•°ï¼šC*4 * C*4ï¼‰
            nn.Conv2d(channels * 4, channels * 4, 1, bias=False),
            nn.BatchNorm2d(channels * 4)
        )
        
        # ========== ä¼˜åŒ–2: å¯¹æ¯”ç‰¹å¾ç”¨æ·±åº¦å¯åˆ†ç¦»å·ç§¯ ==========
        self.contrast_extract = DepthwiseSeparableConv(channels, channels, 3, 1, 1)
        
        # ========== é—¨æ§ç½‘ç»œï¼ˆä¿æŒä¸å˜ï¼Œå‚æ•°æœ¬æ¥å°±å°‘ï¼‰==========
        self.contrast2wt_gate = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(channels, 4, 1),
            nn.Sigmoid()
        )
        
        self.wt2contrast_gate = nn.Sequential(
            nn.Conv2d(channels, channels // 4, 1),
            nn.BatchNorm2d(channels // 4),
            nn.SiLU(inplace=True),
            nn.Conv2d(channels // 4, channels, 1),
            nn.Sigmoid()
        )
        
        self.global_gate = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(channels * 2, 2, 1),
            nn.Softmax(dim=1)
        )
        
        # ========== ä¼˜åŒ–3: ç®€åŒ–ç²¾ç‚¼æ¨¡å— ==========
        # åŸç‰ˆï¼šä¸¤å±‚3x3å·ç§¯
        # ä¼˜åŒ–ï¼šä¸€å±‚æ·±åº¦å¯åˆ†ç¦»å·ç§¯
        self.refine = DepthwiseSeparableConv(channels, channels, 3, 1, 1)
    
    def simple_haar_wavelet(self, x):
        """å¿«é€ŸHaarå°æ³¢å˜æ¢"""
        B, C, H, W = x.shape
        x_00 = x[:, :, 0::2, 0::2]
        x_01 = x[:, :, 0::2, 1::2]
        x_10 = x[:, :, 1::2, 0::2]
        x_11 = x[:, :, 1::2, 1::2]
        
        x_ll = (x_00 + x_01 + x_10 + x_11) / 2
        x_lh = (x_00 + x_01 - x_10 - x_11) / 2
        x_hl = (x_00 - x_01 + x_10 - x_11) / 2
        x_hh = (x_00 - x_01 - x_10 + x_11) / 2
        
        return torch.stack([x_ll, x_lh, x_hl, x_hh], dim=2)
    
    def simple_haar_inverse(self, x_wt):
        """å¿«é€ŸHaaré€†å˜æ¢"""
        x_ll, x_lh, x_hl, x_hh = x_wt[:, :, 0], x_wt[:, :, 1], x_wt[:, :, 2], x_wt[:, :, 3]
        
        x_00 = x_ll + x_lh + x_hl + x_hh
        x_01 = x_ll + x_lh - x_hl - x_hh
        x_10 = x_ll - x_lh + x_hl - x_hh
        x_11 = x_ll - x_lh - x_hl + x_hh
        
        B, C, H, W = x_ll.shape
        x_recon = torch.zeros(B, C, H*2, W*2, device=x_ll.device, dtype=x_ll.dtype)
        x_recon[:, :, 0::2, 0::2] = x_00
        x_recon[:, :, 0::2, 1::2] = x_01
        x_recon[:, :, 1::2, 0::2] = x_10
        x_recon[:, :, 1::2, 1::2] = x_11
        
        return x_recon / 2
    
    def forward(self, x):
        B, C, H, W = x.shape
        
        # å¤„ç†å¥‡æ•°å°ºå¯¸
        pad_h = H % 2
        pad_w = W % 2
        if pad_h or pad_w:
            x_padded = F.pad(x, (0, pad_w, 0, pad_h))
        else:
            x_padded = x
        
        # å°æ³¢åˆ†æ”¯
        x_wt = self.simple_haar_wavelet(x_padded)
        B_wt, C_wt, _, H_wt, W_wt = x_wt.shape
        x_wt_flat = x_wt.reshape(B, C * 4, H_wt, W_wt)
        x_wt_processed = self.wt_process(x_wt_flat)
        
        # å¯¹æ¯”åˆ†æ”¯
        x_contrast = self.contrast_extract(x)
        
        # é—¨æ§äº¤äº’
        subband_gates = self.contrast2wt_gate(x_contrast)
        subband_gates = subband_gates.unsqueeze(2).expand(B, C, 4, 1, 1)
        
        x_wt_reshaped = x_wt_processed.reshape(B, C, 4, H_wt, W_wt)
        x_wt_gated = x_wt_reshaped * subband_gates
        
        x_wt_recon = self.simple_haar_inverse(x_wt_gated)
        x_wt_recon = x_wt_recon[:, :, :H, :W]
        
        contrast_gate = self.wt2contrast_gate(x_wt_recon)
        x_contrast_gated = x_contrast * contrast_gate
        
        # å…¨å±€èåˆ
        fusion_input = torch.cat([x_wt_recon, x_contrast_gated], dim=1)
        global_weights = self.global_gate(fusion_input)
        
        x_fused = (global_weights[:, 0:1] * x_wt_recon + 
                   global_weights[:, 1:2] * x_contrast_gated)
        
        # ç²¾ç‚¼å’Œæ®‹å·®
        out = self.refine(x_fused)
        out = out + x
        
        return out


# ============================================================================
# ç‰ˆæœ¬2: GatedFusion_Tinyï¼ˆä¸­åº¦ä¼˜åŒ–ï¼Œå‚æ•°å‡å°‘50%ï¼‰
# ============================================================================

class GatedFusion_Tiny(nn.Module):
    """
    ä¸­åº¦ä¼˜åŒ–ç‰ˆæœ¬ - å‚æ•°å‡å°‘çº¦50%
    
    ä¼˜åŒ–ç­–ç•¥ï¼š
    1. å‹ç¼©ä¸­é—´é€šé“æ•°ï¼ˆä½¿ç”¨expansion ratioï¼‰
    2. ç§»é™¤ä¸€ä¸ªé—¨æ§åˆ†æ”¯
    3. å…±äº«éƒ¨åˆ†å‚æ•°
    4. æç®€ç²¾ç‚¼æ¨¡å—
    
    æ€§èƒ½é¢„æœŸï¼š
    - å‚æ•°é‡ï¼šåŸç‰ˆ100% â†’ 50%
    - APsæå‡ï¼š+3.5% â†’ +2.5%
    - æ¨ç†é€Ÿåº¦ï¼šæ›´å¿«çº¦30%
    
    é€‚ç”¨åœºæ™¯ï¼š
    - è¾¹ç¼˜è®¾å¤‡
    - å®æ—¶æ€§è¦æ±‚é«˜
    - å‚æ•°é¢„ç®—ç´§å¼ 
    """
    
    def __init__(self, c1, c2, n=1, wt_type='haar', num_heads=4, e=0.5):
        super().__init__()
        
        if c1 != c2:
            self.input_proj = ConvNormLayer(c1, c2, 1, 1, act='silu')
        else:
            self.input_proj = nn.Identity()
        
        self.gated_fusion = GatedInteractiveFusion_Tiny(c2, wt_type, num_heads)
        
        if n > 1:
            self.extra_blocks = nn.ModuleList([
                GatedInteractiveFusion_Tiny(c2, wt_type, num_heads)
                for _ in range(n - 1)
            ])
        else:
            self.extra_blocks = None
    
    def forward(self, x):
        x = self.input_proj(x)
        x = self.gated_fusion(x)
        if self.extra_blocks:
            for block in self.extra_blocks:
                x = block(x)
        return x


class GatedInteractiveFusion_Tiny(nn.Module):
    """ä¸­åº¦ä¼˜åŒ–çš„é—¨æ§äº¤äº’èåˆ"""
    
    def __init__(self, channels, wt_type='haar', num_heads=4, expansion=0.5):
        super().__init__()
        self.channels = channels
        self.use_simple_wavelet = (wt_type == 'haar')
        
        # ========== ä¼˜åŒ–1: å‹ç¼©ä¸­é—´é€šé“æ•° ==========
        hidden_channels = int(channels * expansion)  # å‡å°‘50%é€šé“
        
        # è¾“å…¥é™ç»´
        self.input_compress = nn.Conv2d(channels, hidden_channels, 1, bias=False)
        
        # å°æ³¢å¤„ç†ï¼ˆåœ¨å‹ç¼©ç©ºé—´ï¼‰
        self.wt_process = nn.Sequential(
            nn.Conv2d(hidden_channels * 4, hidden_channels * 4, 3, 
                     padding=1, groups=hidden_channels * 4, bias=False),
            nn.BatchNorm2d(hidden_channels * 4),
            nn.SiLU(inplace=True)
        )
        
        # å¯¹æ¯”ç‰¹å¾ï¼ˆåœ¨å‹ç¼©ç©ºé—´ï¼‰
        self.contrast_extract = nn.Sequential(
            nn.Conv2d(hidden_channels, hidden_channels, 3, 
                     padding=1, groups=hidden_channels, bias=False),
            nn.BatchNorm2d(hidden_channels),
            nn.SiLU(inplace=True)
        )
        
        # ========== ä¼˜åŒ–2: ç®€åŒ–é—¨æ§ï¼ˆåªä¿ç•™å…³é”®çš„ï¼‰==========
        # ç§»é™¤ wt2contrast_gateï¼Œåªä¿ç•™ contrast2wt_gate
        self.gate = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(hidden_channels, 4, 1),  # åªæ§åˆ¶å°æ³¢å­å¸¦
            nn.Sigmoid()
        )
        
        # è¾“å‡ºæ¢å¤
        self.output_expand = nn.Conv2d(hidden_channels, channels, 1, bias=False)
    
    def simple_haar_wavelet(self, x):
        """å¿«é€ŸHaarå°æ³¢å˜æ¢"""
        B, C, H, W = x.shape
        x_00 = x[:, :, 0::2, 0::2]
        x_01 = x[:, :, 0::2, 1::2]
        x_10 = x[:, :, 1::2, 0::2]
        x_11 = x[:, :, 1::2, 1::2]
        
        x_ll = (x_00 + x_01 + x_10 + x_11) / 2
        x_lh = (x_00 + x_01 - x_10 - x_11) / 2
        x_hl = (x_00 - x_01 + x_10 - x_11) / 2
        x_hh = (x_00 - x_01 - x_10 + x_11) / 2
        
        return torch.stack([x_ll, x_lh, x_hl, x_hh], dim=2)
    
    def simple_haar_inverse(self, x_wt):
        """å¿«é€ŸHaaré€†å˜æ¢"""
        x_ll, x_lh, x_hl, x_hh = x_wt[:, :, 0], x_wt[:, :, 1], x_wt[:, :, 2], x_wt[:, :, 3]
        
        x_00 = x_ll + x_lh + x_hl + x_hh
        x_01 = x_ll + x_lh - x_hl - x_hh
        x_10 = x_ll - x_lh + x_hl - x_hh
        x_11 = x_ll - x_lh - x_hl + x_hh
        
        B, C, H, W = x_ll.shape
        x_recon = torch.zeros(B, C, H*2, W*2, device=x_ll.device, dtype=x_ll.dtype)
        x_recon[:, :, 0::2, 0::2] = x_00
        x_recon[:, :, 0::2, 1::2] = x_01
        x_recon[:, :, 1::2, 0::2] = x_10
        x_recon[:, :, 1::2, 1::2] = x_11
        
        return x_recon / 2
    
    def forward(self, x):
        B, C, H, W = x.shape
        identity = x
        
        # ========== åœ¨å‹ç¼©ç©ºé—´å¤„ç† ==========
        x = self.input_compress(x)
        C_hidden = x.shape[1]
        
        # å¤„ç†å¥‡æ•°å°ºå¯¸
        pad_h = H % 2
        pad_w = W % 2
        if pad_h or pad_w:
            x_padded = F.pad(x, (0, pad_w, 0, pad_h))
        else:
            x_padded = x
        
        # å°æ³¢åˆ†æ”¯
        x_wt = self.simple_haar_wavelet(x_padded)
        B_wt, C_wt, _, H_wt, W_wt = x_wt.shape
        x_wt_flat = x_wt.reshape(B, C_hidden * 4, H_wt, W_wt)
        x_wt_processed = self.wt_process(x_wt_flat)
        
        # å¯¹æ¯”åˆ†æ”¯
        x_contrast = self.contrast_extract(x)
        
        # ========== ç®€åŒ–é—¨æ§ï¼šåªç”¨å¯¹æ¯”æ§åˆ¶å°æ³¢ ==========
        gates = self.gate(x_contrast)  # [B, 4, 1, 1]
        gates = gates.unsqueeze(1).expand(B, C_hidden, 4, 1, 1)
        
        x_wt_reshaped = x_wt_processed.reshape(B, C_hidden, 4, H_wt, W_wt)
        x_wt_gated = x_wt_reshaped * gates
        
        x_wt_recon = self.simple_haar_inverse(x_wt_gated)
        x_wt_recon = x_wt_recon[:, :, :H, :W]
        
        # ç®€å•ç›¸åŠ èåˆï¼ˆä¸ç”¨å¤æ‚çš„global gateï¼‰
        x_fused = x_wt_recon + x_contrast
        
        # æ¢å¤åˆ°åŸå§‹é€šé“æ•°
        out = self.output_expand(x_fused)
        out = out + identity
        
        return out


# ============================================================================
# ç‰ˆæœ¬3: GatedFusion_Microï¼ˆæè‡´è½»é‡ï¼Œå‚æ•°å‡å°‘70%ï¼‰
# ============================================================================

class GatedFusion_Micro(nn.Module):
    """
    æè‡´è½»é‡ç‰ˆæœ¬ - å‚æ•°å‡å°‘çº¦70%
    
    ä¼˜åŒ–ç­–ç•¥ï¼š
    1. æœ€å°åŒ–ä¸­é—´é€šé“æ•°ï¼ˆexpansion=0.25ï¼‰
    2. ç§»é™¤æ‰€æœ‰é—¨æ§ï¼Œæ”¹ç”¨ç®€å•åŠ æƒ
    3. å…±äº«å°æ³¢å’Œå¯¹æ¯”å¤„ç†
    4. æ— ç²¾ç‚¼æ¨¡å—
    
    æ€§èƒ½é¢„æœŸï¼š
    - å‚æ•°é‡ï¼šåŸç‰ˆ100% â†’ 30%
    - APsæå‡ï¼š+3.5% â†’ +1.5~2.0%
    - æ¨ç†é€Ÿåº¦ï¼šæ›´å¿«çº¦50%
    
    é€‚ç”¨åœºæ™¯ï¼š
    - æåº¦èµ„æºå—é™
    - ç§»åŠ¨ç«¯/åµŒå…¥å¼è®¾å¤‡
    - éœ€è¦æå¿«æ¨ç†é€Ÿåº¦
    - å¯ä»¥æ¥å—æ€§èƒ½è½»å¾®ä¸‹é™
    """
    
    def __init__(self, c1, c2, n=1, wt_type='haar', num_heads=4, e=0.5):
        super().__init__()
        
        if c1 != c2:
            # ä½¿ç”¨æ·±åº¦å¯åˆ†ç¦»å·ç§¯å¯¹é½
            self.input_proj = DepthwiseSeparableConv(c1, c2, 1, 1, 0)
        else:
            self.input_proj = nn.Identity()
        
        self.gated_fusion = GatedInteractiveFusion_Micro(c2, wt_type)
        
        if n > 1:
            self.extra_blocks = nn.ModuleList([
                GatedInteractiveFusion_Micro(c2, wt_type)
                for _ in range(n - 1)
            ])
        else:
            self.extra_blocks = None
    
    def forward(self, x):
        x = self.input_proj(x)
        x = self.gated_fusion(x)
        if self.extra_blocks:
            for block in self.extra_blocks:
                x = block(x)
        return x


class GatedInteractiveFusion_Micro(nn.Module):
    """æè‡´è½»é‡çš„é—¨æ§äº¤äº’èåˆ"""
    
    def __init__(self, channels, wt_type='haar', expansion=0.25):
        super().__init__()
        self.channels = channels
        
        # ========== ä¼˜åŒ–1: æå°çš„ä¸­é—´é€šé“æ•° ==========
        hidden_channels = max(int(channels * expansion), 16)  # è‡³å°‘16é€šé“
        
        # è¾“å…¥é™ç»´ï¼ˆæ·±åº¦å¯åˆ†ç¦»ï¼‰
        self.compress = nn.Sequential(
            nn.Conv2d(channels, channels, 3, padding=1, groups=channels, bias=False),
            nn.BatchNorm2d(channels),
            nn.Conv2d(channels, hidden_channels, 1, bias=False),
            nn.BatchNorm2d(hidden_channels),
            nn.SiLU(inplace=True)
        )
        
        # ========== ä¼˜åŒ–2: å…±äº«å¤„ç†ï¼ˆå°æ³¢å’Œå¯¹æ¯”å…±ç”¨ï¼‰==========
        self.shared_process = nn.Sequential(
            nn.Conv2d(hidden_channels, hidden_channels, 3, 
                     padding=1, groups=hidden_channels, bias=False),
            nn.BatchNorm2d(hidden_channels),
            nn.SiLU(inplace=True)
        )
        
        # ========== ä¼˜åŒ–3: æç®€èåˆï¼ˆå¯å­¦ä¹ æƒé‡ï¼‰==========
        self.fusion_weight = nn.Parameter(torch.tensor([0.5, 0.5]))
        
        # è¾“å‡ºæ¢å¤ï¼ˆæ·±åº¦å¯åˆ†ç¦»ï¼‰
        self.expand = nn.Sequential(
            nn.Conv2d(hidden_channels, hidden_channels, 3, 
                     padding=1, groups=hidden_channels, bias=False),
            nn.BatchNorm2d(hidden_channels),
            nn.Conv2d(hidden_channels, channels, 1, bias=False),
            nn.BatchNorm2d(channels)
        )
    
    def simple_haar_wavelet(self, x):
        """å¿«é€ŸHaarå°æ³¢å˜æ¢ï¼ˆåªä¿ç•™LLå’ŒHHï¼‰"""
        B, C, H, W = x.shape
        x_00 = x[:, :, 0::2, 0::2]
        x_01 = x[:, :, 0::2, 1::2]
        x_10 = x[:, :, 1::2, 0::2]
        x_11 = x[:, :, 1::2, 1::2]
        
        # åªä¿ç•™ä½é¢‘å’Œé«˜é¢‘å¯¹è§’
        x_ll = (x_00 + x_01 + x_10 + x_11) / 2  # ä½é¢‘
        x_hh = (x_00 - x_01 - x_10 + x_11) / 2  # å¯¹è§’é«˜é¢‘
        
        return x_ll, x_hh
    
    def simple_haar_inverse_simplified(self, x_ll, x_hh):
        """ç®€åŒ–çš„Haaré€†å˜æ¢"""
        x_00 = x_ll + x_hh
        x_01 = x_ll - x_hh
        x_10 = x_ll - x_hh
        x_11 = x_ll + x_hh
        
        B, C, H, W = x_ll.shape
        x_recon = torch.zeros(B, C, H*2, W*2, device=x_ll.device, dtype=x_ll.dtype)
        x_recon[:, :, 0::2, 0::2] = x_00
        x_recon[:, :, 0::2, 1::2] = x_01
        x_recon[:, :, 1::2, 0::2] = x_10
        x_recon[:, :, 1::2, 1::2] = x_11
        
        return x_recon / 2
    
    def forward(self, x):
        B, C, H, W = x.shape
        identity = x
        
        # é™ç»´åˆ°å‹ç¼©ç©ºé—´
        x = self.compress(x)
        
        # å¤„ç†å¥‡æ•°å°ºå¯¸
        pad_h = H % 2
        pad_w = W % 2
        if pad_h or pad_w:
            x_padded = F.pad(x, (0, pad_w, 0, pad_h))
        else:
            x_padded = x
        
        # ========== ç®€åŒ–å°æ³¢ï¼šåªç”¨LLå’ŒHH ==========
        x_ll, x_hh = self.simple_haar_wavelet(x_padded)
        x_wt = self.shared_process(x_ll + x_hh)  # åˆå¹¶å¤„ç†
        
        # ========== å¯¹æ¯”ç‰¹å¾ ==========
        x_contrast = self.shared_process(x)
        
        # ========== æç®€èåˆï¼šå¯å­¦ä¹ åŠ æƒ ==========
        w = torch.softmax(self.fusion_weight, dim=0)
        x_fused = w[0] * x_wt + w[1] * x_contrast
        
        # æ¢å¤åˆ°åŸå§‹ç©ºé—´
        out = self.expand(x_fused)
        out = out + identity
        
        return out
